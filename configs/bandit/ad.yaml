# Tuned
attention_dropout: 0.1
beta1: 0.82
dropout: 0.1
label_smoothing: 0.005
learning_rate: 1.1e-5
weight_decay: 1.5e-4

# wandb
project: "Headless-AD"
group: bandit_ad_optimal
job_type: "debug"
name: null

# seeds
train_seed: 0
eval_seed: 100

# data settings
env_name: "MultiArmedBanditBernoulli"
num_train_envs: 10_000
num_env_steps: 300
train_min_arms: 4
train_max_arms: 20
eval_more_arms_list: []
data_generation_algo: "thompson"
ucb_alpha: 0.3 # ucb
learning_histories_path: "trajectories"

num_eval_envs: 200
eval_every: 5_00
log_every: 100

num_train_steps: 50_000

# Model Params
seq_len: 300
layer_norm_bias: True
token_embed_dim: 128
d_model: 512
num_layers: 4
num_heads: 64

# Training params
batch_size: 32
warmup_ratio: 0.1
clip_grad_norm: 5
get_action_type: "sample"
train_on_mixed: False
rand_select_in_ucb: True

# New
rotary_percentage: 1.0
parallel_residual: False
_norm_class: "FusedRMSNorm"
_mlp_class: "LLaMAMLP"
shared_attention_norm: False
# intermediate_size: 102

# Device
device: "cuda"
autocast_dtype: "bf16"

# Where to save data for experiment visualizations
logs_dir: "logs"